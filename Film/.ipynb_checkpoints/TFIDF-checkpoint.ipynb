{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import ast\n",
    "import gzip\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "import editdistance\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Film/Film_tropes_dataset.json\", 'r', encoding='utf-8') as json_file:  \n",
    "    movie_tropes_data = json.loads(json_file.read())\n",
    "with open(\"Literature/Literature_tropes_dataset.json\", 'r', encoding='utf-8') as json_file:  \n",
    "    book_tropes_data = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drumline',\n",
       " 'antoniasline',\n",
       " 'damienomenii',\n",
       " 'bandits',\n",
       " 'roadhouse',\n",
       " 'enemyatthegates',\n",
       " 'whatseatinggilbertgrape',\n",
       " 'fatherofthebride1991',\n",
       " 'agnesofgod',\n",
       " 'sophieschollthefinaldays']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(movie_tropes_data.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affinity',\n",
       " 'sentencedtoprism',\n",
       " 'nostromo',\n",
       " 'aroomwithaview',\n",
       " 'revolutionaryroad',\n",
       " 'terminalworld',\n",
       " 'thehellboundheart',\n",
       " 'thebrokensword',\n",
       " 'armor',\n",
       " 'alongfortheride']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(book_tropes_data.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries for translating simplified names to full names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/movie_s2f.pickle', 'rb') as handle:\n",
    "    movie_s2o = pickle.load(handle)\n",
    "    \n",
    "unused = set(movie_s2o) - set(movie_tropes_data.keys())\n",
    "for u in unused:\n",
    "    del movie_s2o[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/book_titles_s2f.pickle', 'rb') as handle:\n",
    "    book_s2o = pickle.load(handle)\n",
    "    \n",
    "unused = set(book_s2o) - set(book_tropes_data.keys())\n",
    "for u in unused:\n",
    "    del book_s2o[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert_dict(d: Dict[str, str]):\n",
    "    retval = dict()\n",
    "    for k, v in d.items():\n",
    "        retval[v] = k\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_s2o_inverted = invert_dict(movie_s2o)\n",
    "book_s2o_inverted = invert_dict(book_s2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_similar_word(wordlist: List[str], word: str):\n",
    "    \"\"\"\n",
    "    Helper function for matching query to in-database title\n",
    "    \"\"\"\n",
    "    min_val = 99999\n",
    "    retval = None\n",
    "    for w in wordlist:\n",
    "        dist = editdistance.eval(w, word)\n",
    "        if dist < min_val:\n",
    "#             print(\"Swapping {} for {}\".format(retval, w))\n",
    "#             print(\"{} is the edit distance between {} and {}\".format(dist, w, word))\n",
    "            min_val = dist\n",
    "            retval = w\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = list(book_tropes_data.keys())\n",
    "movies = list(movie_tropes_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_index_books = defaultdict(list)\n",
    "for book, trope_list in book_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_books[trope].append(book)\n",
    "\n",
    "inverted_index_movies = defaultdict(list)\n",
    "for movie, trope_list in movie_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_movies[trope].append(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [movie_tropes_data, book_tropes_data]\n",
    "inverted_indices = [inverted_index_movies, inverted_index_books]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_norm(tropes_data, \n",
    "             inverted_index, \n",
    "             idf: str=None):\n",
    "    \"\"\"\n",
    "    Note the custom formulae for normalization: avoids rewarding when norms[document] is small (e.g. <1)\n",
    "    \"\"\"\n",
    "    if idf == \"inverse\":\n",
    "        f = lambda trope: (1.0 / len(inverted_index[trope])) **2\n",
    "    elif idf == \"log\":\n",
    "        f = lambda trope: (1.0/(1+np.log(len(inverted_index[trope]))))**2\n",
    "    elif idf is None:\n",
    "        f = lambda trope: 1\n",
    "    else:\n",
    "        raise Exception(\"Invalid IDF\")\n",
    "                                                                                \n",
    "    norms = defaultdict(int)\n",
    "    for document, trope_list in tropes_data.items():\n",
    "        for trope in trope_list:\n",
    "            norms[document] += f(trope)\n",
    "#             \n",
    "        norms[document] = 0.1*(norms[document]) + 2 \n",
    "#         norms[document] = math.sqrt(norms[document])\n",
    "    \n",
    "    return norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idf_func(inverted_indices: List[Dict[str, str]], idf: str):\n",
    "    if idf == \"inverse\":\n",
    "        return lambda trope: (1.0 / len(inverted_indices[0][trope])) * (1.0 / len(inverted_indices[1][trope]))\n",
    "    elif idf == \"log\":\n",
    "        return lambda trope: (1.0/(1+np.log(len(inverted_indices[0][trope])))) * (1.0/(1+np.log(len(inverted_indices[1][trope]))))\n",
    "    elif idf is None:\n",
    "        return lambda trope: 1\n",
    "    else:\n",
    "        raise Exception(\"Invalid IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_with_num_tropes(doc_scores: List[Tuple], \n",
    "                           trope_contributions: Dict[str, Dict[str, int]], \n",
    "                           num_tropes: int):\n",
    "    \"\"\"\n",
    "    Exclude documents where number of similar tropes is <= [num_tropes]\n",
    "    \"\"\"\n",
    "    return list(filter(lambda ds: len(trope_contributions[ds[0]]) > num_tropes, doc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_relevant(datasets: List[Dict],\n",
    "                  inverted_indices: List[Dict],\n",
    "                  query: str, \n",
    "                  input_category: str,\n",
    "                  result_category: str,\n",
    "                  normalize: bool=True, \n",
    "                  idf:str=None,\n",
    "                  min_df:int=0\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    THE main TF-IDF function\n",
    "    \n",
    "    \"\"\"\n",
    "    idx = {\"movie\": 0, \"book\": 1}\n",
    "    \n",
    "    input_idx = idx[input_category]\n",
    "    result_idx = idx[result_category]\n",
    "    \n",
    "    input_dataset = datasets[input_idx]\n",
    "    inverted_index = inverted_indices[input_idx]\n",
    "    \n",
    "    f = get_idf_func(inverted_indices=inverted_indices, idf=idf)\n",
    "    \n",
    "    # Correcting search query to database title\n",
    "    if query not in input_dataset:\n",
    "        print(\"Could not find title: {}\".format(query))\n",
    "        most_similar_word = get_most_similar_word(input_dataset.keys(), query)\n",
    "        print(\"Querying database for: {}\".format(most_similar_word))\n",
    "        query = most_similar_word\n",
    "\n",
    "    query_vec = input_dataset[query]\n",
    "    \n",
    "    doc_scores = defaultdict(int)  \n",
    "    trope_contributions = defaultdict(dict) # record weightage of each trope contributions\n",
    "    \n",
    "    # Update accumulators\n",
    "    for trope in query_vec:\n",
    "        if len(inverted_indices[input_idx][trope]) < min_df or len(inverted_indices[result_idx][trope]) < min_df:\n",
    "            continue\n",
    "            \n",
    "        postings = inverted_indices[result_idx][trope]\n",
    "        for doc in postings:\n",
    "            weight_update = f(trope)\n",
    "            doc_scores[doc] += weight_update\n",
    "            trope_contributions[doc][trope] = weight_update\n",
    "\n",
    "    # Normalize\n",
    "    if normalize:\n",
    "        norms = doc_norm(datasets[result_idx], \n",
    "                 inverted_indices[result_idx], \n",
    "                 idf=idf)\n",
    "        for d in doc_scores:\n",
    "            if norms[d] != 0:\n",
    "                doc_scores[d] /= norms[d]\n",
    "    \n",
    "    doc_idx_scores = sorted(doc_scores.items(), key=lambda x:x[1], reverse=True)\n",
    "    doc_scores = [(doc, score) for doc, score in doc_idx_scores if score > 0]\n",
    "    \n",
    "    doc_scores = filter_with_num_tropes(doc_scores, trope_contributions, num_tropes=1)\n",
    "    return doc_scores[:10], trope_contributions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeandagain ['MentalTimeTravel', 'RippleEffectProofMemory', 'RetGone', 'ForegoneConclusion']\n",
      "\n",
      "\n",
      "thenightcircus ['BoyMeetsGirl', 'MakeAWish', 'WeirdnessCensor', 'LaserGuidedAmnesia', 'EarlyBirdCameo', 'StarCrossedLovers', 'AllThereInTheManual', 'OnlyKnownByTheirNickname', 'ParentalAbandonment', 'TemptingFate']\n",
      "\n",
      "\n",
      "rage ['PantyShot', 'AdultsAreUseless', 'NoodleIncident', 'ArcWords', 'KarmaHoudini', 'Foreshadowing', 'ChekhovsGun', 'ShoutOut']\n",
      "\n",
      "\n",
      "beloved ['MagicRealism', 'GilliganCut', 'IWantMyBelovedToBeHappy', 'MindScrew', 'ParentalAbandonment', 'HopeSpot', 'HeroicBSOD', 'TitleDrop']\n",
      "\n",
      "\n",
      "fireandhemlock ['ThisIsReality', 'LaserGuidedAmnesia', 'MaybeEverAfter', 'MindScrew', 'ParentalAbandonment', 'ShoutOut']\n",
      "\n",
      "\n",
      "fences ['WhereAreTheyNow', 'HairTriggerTemper', 'ParentalAbandonment', 'MissingMom', 'MeaningfulName']\n",
      "\n",
      "\n",
      "thetruthaboutforever ['RaceForYourLove', 'LoveEpiphany', 'EveryoneCanSeeIt', 'RedOniBlueOni', 'ThoseTwoGuys', 'ContrivedCoincidence']\n",
      "\n",
      "\n",
      "blackbeauty ['BigDamnReunion', 'IWillFindYou', 'BeCarefulWhatYouWishFor', 'AdaptationExpansion', 'ForegoneConclusion', 'TemptingFate', 'EarnYourHappyEnding', 'MeaningfulName']\n",
      "\n",
      "\n",
      "thebookoflies ['WhereTheHellIsSpringfield', 'MindScrew', 'OnlyKnownByTheirNickname', 'ArcWords', 'TitleDrop']\n",
      "\n",
      "\n",
      "lockandkey ['CryCute', 'EveryoneCanSeeIt', 'BaitAndSwitch', 'ParentalAbandonment', 'ContrivedCoincidence']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles, contributions = find_relevant(datasets=datasets,\n",
    "                                      inverted_indices=inverted_indices,\n",
    "                                      query=\"yourname\", \n",
    "                                      input_category=\"movie\",\n",
    "                                      result_category=\"book\",\n",
    "                                      min_df=5,\n",
    "                                      normalize=True,\n",
    "                                      idf=\"log\"\n",
    "                                     )\n",
    "\n",
    "for title in titles:\n",
    "    important_tropes = sorted(contributions[title[0]].items(), key= lambda x : x[1], reverse=True)\n",
    "    important_tropes = [trope for trope, score in important_tropes if score > 0]\n",
    "    print(title[0], important_tropes[:10])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "astarisborn ['Jerkass', 'MeaningfulEcho', 'FourthDateMarriage', 'PygmalionPlot', 'TheAlcoholic', 'ForgottenTrope', 'SuicideBySea', 'AwardBaitSong', 'IWantMyBelovedToBeHappy', 'SettingUpdate']\n",
    "\n",
    "driven ['Jerkass', 'AwardBaitSong']\n",
    "\n",
    "cominghome ['SuicideBySea', 'DrivenToSuicide']\n",
    "\n",
    "patchadams ['Jerkass', 'AwardBaitSong', 'DrivenToSuicide']\n",
    "\n",
    "thevow ['Jerkass', 'IWantMyBelovedToBeHappy']\n",
    "\n",
    "broadwaydannyrose ['MeaningfulEcho', 'TheAlcoholic', 'DrivenToSuicide']\n",
    "\n",
    "augustrush ['Jerkass', 'MeaningfulEcho', 'SettingUpdate']\n",
    "\n",
    "crazyheart ['Jerkass', 'TheAlcoholic']\n",
    "\n",
    "anaffairtoremember ['FourthDateMarriage', 'IWantMyBelovedToBeHappy']\n",
    "\n",
    "poeticjustice ['Jerkass', 'TheAlcoholic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
