{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import ast\n",
    "import gzip\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "import editdistance\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Film/Film_tropes_dataset3.json\", 'r') as f:  \n",
    "    movie_tropes_data = json.load(f)\n",
    "with open(\"Literature/Literature_tropes_dataset3.json\", 'r') as f:  \n",
    "    book_tropes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drumline',\n",
       " \"Antonia's Line\",\n",
       " 'Damien: Omen II',\n",
       " 'Bandits',\n",
       " 'Road House',\n",
       " 'Enemy at the Gates',\n",
       " \"What's Eating Gilbert Grape\",\n",
       " 'Father of the Bride',\n",
       " 'Agnes of God',\n",
       " 'Sophie Scholl: The Final Days']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(movie_tropes_data.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Affinity',\n",
       " 'Sentenced To Prism',\n",
       " 'Nostromo',\n",
       " 'A Room With A View',\n",
       " 'Revolutionary Road',\n",
       " 'Terminal World',\n",
       " 'The Hellbound Heart',\n",
       " 'The Broken Sword',\n",
       " 'Armor',\n",
       " 'Along For The Ride']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(book_tropes_data.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries for translating simplified names to full names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BiTheWay',\n",
       " 'BitchInSheepsClothing',\n",
       " 'YourCheatingHeart',\n",
       " 'Gayngst',\n",
       " 'AdaptationalAttractiveness',\n",
       " 'SpookySeance',\n",
       " 'HairOfGoldHeartOfGold',\n",
       " 'BatmanGambit',\n",
       " 'CanonForeigner',\n",
       " 'TheFarmerAndTheViper',\n",
       " 'PsychicPowers',\n",
       " 'OldMaid',\n",
       " 'VictorianLondon',\n",
       " 'ButchLesbian',\n",
       " 'DrivenToSuicide',\n",
       " 'EeriePaleSkinnedBrunette',\n",
       " 'UnwittingPawn',\n",
       " 'DarkAndTroubledPast',\n",
       " 'Angst',\n",
       " 'StalkerWithACrush',\n",
       " 'QueerRomance',\n",
       " 'AnachronicOrder',\n",
       " 'MyBelovedSmother',\n",
       " 'TheDitz',\n",
       " 'HeroicBSOD',\n",
       " 'TheReveal']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_tropes_data['Affinity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/movie_s2f.pickle', 'rb') as handle:\n",
    "    movie_s2o = pickle.load(handle)\n",
    "    \n",
    "unused = set(movie_s2o) - set(movie_tropes_data.keys())\n",
    "for u in unused:\n",
    "    del movie_s2o[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickles/book_titles_s2f.pickle', 'rb') as handle:\n",
    "    book_s2o = pickle.load(handle)\n",
    "    \n",
    "unused = set(book_s2o) - set(book_tropes_data.keys())\n",
    "for u in unused:\n",
    "    del book_s2o[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert_dict(d: Dict[str, str]):\n",
    "    retval = dict()\n",
    "    for k, v in d.items():\n",
    "        retval[v] = k\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_s2o_inverted = invert_dict(movie_s2o)\n",
    "book_s2o_inverted = invert_dict(book_s2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_most_similar_word(wordlist: List[str], word: str):\n",
    "    \"\"\"\n",
    "    Helper function for matching query to in-database title\n",
    "    \"\"\"\n",
    "    min_val = 99999\n",
    "    retval = None\n",
    "    for w in wordlist:\n",
    "        dist = editdistance.eval(w, word)\n",
    "        if dist < min_val:\n",
    "#             print(\"Swapping {} for {}\".format(retval, w))\n",
    "#             print(\"{} is the edit distance between {} and {}\".format(dist, w, word))\n",
    "            min_val = dist\n",
    "            retval = w\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = list(book_tropes_data.keys())\n",
    "movies = list(movie_tropes_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverted_index_books = defaultdict(list)\n",
    "for book, trope_list in book_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_books[trope].append(book)\n",
    "\n",
    "inverted_index_movies = defaultdict(list)\n",
    "for movie, trope_list in movie_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_movies[trope].append(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [movie_tropes_data, book_tropes_data]\n",
    "inverted_indices = [inverted_index_movies, inverted_index_books]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_norm(tropes_data, \n",
    "             inverted_index, \n",
    "             idf: str=None):\n",
    "    \"\"\"\n",
    "    Note the custom formulae for normalization: avoids rewarding when norms[document] is small (e.g. <1)\n",
    "    \"\"\"\n",
    "    if idf == \"inverse\":\n",
    "        f = lambda trope: (1.0 / len(inverted_index[trope])) **2\n",
    "    elif idf == \"log\":\n",
    "        f = lambda trope: (1.0/(1+np.log(len(inverted_index[trope]))))**2\n",
    "    elif idf is None:\n",
    "        f = lambda trope: 1\n",
    "    else:\n",
    "        raise Exception(\"Invalid IDF\")\n",
    "                                                                                \n",
    "    norms = defaultdict(int)\n",
    "    for document, trope_list in tropes_data.items():\n",
    "        for trope in trope_list:\n",
    "            norms[document] += f(trope)\n",
    "#             \n",
    "#         norms[document] = 0.1*(norms[document]) + 2 \n",
    "        norms[document] = math.sqrt(norms[document])\n",
    "    \n",
    "    return norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idf_func(input_inverted_index, result_inverted_index, idf: str):\n",
    "    if idf == \"inverse\":\n",
    "        return lambda trope: (1.0 / len(input_inverted_index[trope])) * (1.0 / len(result_inverted_index[trope]))\n",
    "    elif idf == \"log\":\n",
    "        return lambda trope: (1.0/(1+np.log(len(input_inverted_index[trope])))) * (1.0/(1+np.log(len(result_inverted_index[trope]))))\n",
    "    elif idf is None:\n",
    "        return lambda trope: 1\n",
    "    else:\n",
    "        raise Exception(\"Invalid IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_with_num_tropes(doc_scores: List[Tuple], \n",
    "                           trope_contributions: Dict[str, Dict[str, int]], \n",
    "                           num_tropes: int):\n",
    "    \"\"\"\n",
    "    Exclude documents where number of similar tropes is <= [num_tropes]\n",
    "    \"\"\"\n",
    "    return list(filter(lambda ds: len(trope_contributions[ds[0]]) >= num_tropes, doc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_relevant(datasets: List[Dict],\n",
    "                  inverted_indices: List[Dict],\n",
    "                  query: str, \n",
    "                  input_category: str,\n",
    "                  result_category: str,\n",
    "                  normalize: bool=True, \n",
    "                  idf:str=None,\n",
    "                  min_df:int=0\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    THE main TF-IDF function\n",
    "    \n",
    "    \"\"\"\n",
    "    idx = {\"movie\": 0, \"book\": 1}\n",
    "    \n",
    "    input_idx = idx[input_category]\n",
    "    result_idx = idx[result_category]\n",
    "    \n",
    "    input_dataset = datasets[input_idx]\n",
    "    \n",
    "    f = get_idf_func(input_inverted_index=inverted_indices[input_idx], \n",
    "                     result_inverted_index=inverted_indices[result_idx], \n",
    "                     idf=idf)\n",
    "    \n",
    "    # Correcting search query to database title\n",
    "    if query not in input_dataset:\n",
    "        print(\"Could not find title: {}\".format(query))\n",
    "        most_similar_word = get_most_similar_word(input_dataset.keys(), query)\n",
    "        print(\"Querying database for: {}\".format(most_similar_word))\n",
    "        query = most_similar_word\n",
    "\n",
    "    query_vec = input_dataset[query]\n",
    "    \n",
    "    doc_scores = defaultdict(int)  \n",
    "    trope_contributions = defaultdict(dict) # record weightage of each trope contributions\n",
    "    \n",
    "    # Update accumulators\n",
    "    for trope in query_vec:\n",
    "        if len(inverted_indices[input_idx][trope]) < min_df or len(inverted_indices[result_idx][trope]) < min_df:\n",
    "            continue\n",
    "            \n",
    "        postings = inverted_indices[result_idx][trope]\n",
    "        for doc in postings:\n",
    "            weight_update = f(trope)\n",
    "            doc_scores[doc] += weight_update\n",
    "            trope_contributions[doc][trope] = weight_update\n",
    "\n",
    "    # Normalize\n",
    "    if normalize:\n",
    "        norms = doc_norm(datasets[result_idx], \n",
    "                 inverted_indices[result_idx], \n",
    "                 idf=idf)\n",
    "        for d in doc_scores:\n",
    "            if norms[d] != 0:\n",
    "                doc_scores[d] /= norms[d]\n",
    "    \n",
    "    doc_idx_scores = sorted(doc_scores.items(), key=lambda x:x[1], reverse=True)\n",
    "    doc_scores = [(doc, score) for doc, score in doc_idx_scores if score > 0]\n",
    "    \n",
    "    doc_scores = filter_with_num_tropes(doc_scores, trope_contributions, num_tropes=5)\n",
    "    return doc_scores[:10], trope_contributions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Deathly Hallows: Part 1 ['NoManShouldHaveThisPower', 'GottaCatchThemAll', 'FollowTheWhiteRabbit', 'GottaKillThemAll', 'SupportingLeader', 'MuggedForDisguise', 'BackForTheFinale', 'SleepCute', 'LamePunReaction', 'FullNameUltimatum']\n",
      "\n",
      "\n",
      "Harry Potter and the Deathly Hallows: Part 2 ['NoManShouldHaveThisPower', 'GottaCatchThemAll', 'FollowTheWhiteRabbit', 'GottaKillThemAll', 'SupportingLeader', 'MuggedForDisguise', 'BackForTheFinale', 'SleepCute', 'LamePunReaction', 'FullNameUltimatum']\n",
      "\n",
      "\n",
      "Harry Potter and the Deathly Hallows ['NoManShouldHaveThisPower', 'GottaCatchThemAll', 'FollowTheWhiteRabbit', 'GottaKillThemAll', 'SupportingLeader', 'MuggedForDisguise', 'BackForTheFinale', 'SleepCute', 'LamePunReaction', 'FullNameUltimatum']\n",
      "\n",
      "\n",
      "Avengers: Infinity War - Part I ['CharactersDroppingLikeFlies', 'InfinityPlusOneSword', 'VillainOpeningScene', 'RetiredMonster', 'HeroicSuicide', 'SpoilerCover', 'AchillesInHisTent', 'YoureInsane', 'Deuteragonist', 'GrandFinale']\n",
      "\n",
      "\n",
      "Batman v Superman: Dawn of Justice ['BuryingASubstitute', 'NoManShouldHaveThisPower', 'BluntYes', 'FullNameUltimatum', 'YoureInsane', 'PinballProtagonist', 'SaveTheVillain', 'OnceMoreWithClarity', 'PuttingOnTheReich', 'BroughtDownToNormal']\n",
      "\n",
      "\n",
      "The Avengers ['BallroomBlitz', 'TheDeadHaveNames', 'VillainOpeningScene', 'KirkSummation', 'DidYouJustScamCthulhu', 'HatePlague', 'ChangedMyMindKid', 'DeathIsDramatic', 'YouJustToldMe', 'BluntYes']\n",
      "\n",
      "\n",
      "Transformers: Dark of the Moon ['SuddenlyVoiced', 'TheQuisling', 'TheBigDamnKiss', 'ShooOutTheClowns', 'LetsGetDangerous', 'EvilCannotComprehendGood', 'RetiredBadass', 'DealWithTheDevil', 'CrouchingMoronHiddenBadass', 'SealedEvilInACan']\n",
      "\n",
      "\n",
      "The World's End ['SelfHealingPhlebotinum', 'TheQuisling', 'TheCuckoolanderWasRight', 'PreAsskickingOneLiner', 'Understatement', 'GrowingUpSucks', 'MomentKiller', 'MundaneMadeAwesome', 'SayMyName', 'KickTheSonOfABitch']\n",
      "\n",
      "\n",
      "Without a Paddle ['TakeOffYourClothes', 'HorribleCampingTrip', 'NakedPeopleAreFunny', 'MamaBear', 'IronicEcho', 'HoistByHisOwnPetard', 'NoodleIncident', 'OhCrap', 'ChekhovsGun']\n",
      "\n",
      "\n",
      "Harry Brown ['Understatement', 'ImperialStormtrooperMarksmanshipAcademy', 'TraumaCongaLine', 'JackBauerInterrogationTechnique', 'LetsGetDangerous', 'RetiredBadass', 'AntiVillain', 'DarkerAndEdgier', 'LaserGuidedKarma', 'TheReveal']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles, contributions = find_relevant(datasets=datasets,\n",
    "                                      inverted_indices=inverted_indices,\n",
    "                                      query=\"Harry Potter and the Deathly Hallows\", \n",
    "                                      input_category=\"book\",\n",
    "                                      result_category=\"movie\",\n",
    "                                      min_df=3,\n",
    "                                      normalize=True,\n",
    "                                      idf=\"log\"\n",
    "                                     )\n",
    "\n",
    "for title in titles:\n",
    "    important_tropes = sorted(contributions[title[0]].items(), key= lambda x : x[1], reverse=True)\n",
    "    important_tropes = [trope for trope, score in important_tropes if score > 0]\n",
    "    print(title[0], important_tropes[:10])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
